{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omhpatel7/4ML3/blob/main/patelo14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practicing PCA on Two Datasets\n",
        "In this exercise, we explore the application of PCA on two different datasets. One of them is synthetic and the other one is available through the sklearn package.\n",
        "\n",
        "# Submission\n",
        "- There are four tasks for you.\n",
        "- Report the results and answer the questions in the pdf file that you would submit along with your other solutions.\n",
        "- Additionally, submit your code in the same Jupiter notebook format. (keep the overal format of the notebook unchanged)\n"
      ],
      "metadata": {
        "id": "mCkRpL8cuKrx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Packages\n",
        "First of all, let's import the packages we need for this assignment."
      ],
      "metadata": {
        "id": "3HTz0s9Y0eO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.linalg import svd\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "import pandas as pd\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.decomposition import KernelPCA\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "P8E_FRJZ0gkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datasets:\n",
        "First dataset is LFW (Labeled Faces in the Wild) dataset. And the second one is a synthetic dataset that will be explained in a few"
      ],
      "metadata": {
        "id": "-QlGTa3R06T0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First Dataset: Labeled Faces in the Wild (LFW)\n",
        "\n",
        "The **Labeled Faces in the Wild (LFW)** dataset is a collection of face images. This dataset contains images of famous individuals collected from the web, with each image labeled by the identity of the person in the image.\n",
        "\n",
        "#### Features:\n",
        "- **Image data**: Each image is a grayscale 2D image of size 62x47 pixels, representing a person's face.\n",
        "- **Label**: The name of the person in the image, which serves as the class label.\n",
        "\n",
        "#### Dataset Properties:\n",
        "- **Number of Samples**:\n",
        "  - Full dataset: 13,233 images.\n",
        "  - Reduced version (available via `sklearn`): 1,288 images.\n",
        "  - \"George W Bush\" class: 530 images.\n",
        "- **Number of Classes**:\n",
        "  - Full dataset: 5749 unique individuals, with varying numbers of images per person.\n",
        "  - Reduced version (available via `sklearn`): 7 classes.\n",
        "- **Image Size**: Each image is 62x47 pixels (grayscale), giving 2,914 features per image (62 Ã— 47 = 2,914).\n",
        "- **Format**: The dataset provides images as NumPy arrays and labels as strings.\n"
      ],
      "metadata": {
        "id": "emRFl-yw2-on"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loading LFW dataset:"
      ],
      "metadata": {
        "id": "mnm1qUQN6Pir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.5)\n",
        "n_samples_LFW, image_height, image_width = lfw_people.images.shape\n",
        "\n",
        "X_LFW = lfw_people.data\n",
        "Y_LFW = lfw_people.target\n",
        "\n",
        "Y_names_LFW = lfw_people.target_names\n",
        "n_classes_LFW = Y_names_LFW.shape[0]\n",
        "\n",
        "print(\"Dataset properties:\")\n",
        "print(\"\\t Number of data points: %d\" % X_LFW.shape[0])\n",
        "print(\"\\t Number of features: %d\" % X_LFW.shape[1])\n",
        "print(\"\\t Number of classes: %d\" % n_classes_LFW)\n",
        "print(\"\\t Width of each image: %d\" % image_width)\n",
        "print(\"\\t Height of each image: %d\" % image_height)"
      ],
      "metadata": {
        "id": "SmLyUDHn3UAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualization:"
      ],
      "metadata": {
        "id": "fEevwQvC7PVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_faces(images, labels, names, n_row, n_col):\n",
        "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
        "    f = plt.figure(figsize=(8,3))\n",
        "    for i in range(n_row * n_col):\n",
        "        subfigure = f.add_subplot(n_row, n_col, i + 1)\n",
        "        subfigure.imshow(images[i].reshape((image_height, image_width)), cmap=plt.cm.gray)\n",
        "        subfigure.set_title(names[labels[i]], fontsize=10)\n",
        "        # Removing the axes\n",
        "        plt.xticks(())\n",
        "        plt.yticks(())\n",
        "    plt.show()\n",
        "\n",
        "plot_faces(X_LFW, Y_LFW, Y_names_LFW, 2, 5)"
      ],
      "metadata": {
        "id": "s72Mqh2l7OKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Second Dataset: Two Noisy Circles (TNC)\n",
        "\n",
        "\n",
        "This dataset contains synthetic samples of two noisy circles in 2D space. Each circle has a different radius, and noise is added to the points to simulate imperfect real-world data.\n",
        "\n",
        "#### Features:\n",
        "- **coord_x**: The x-coordinate of the data point in 2D space.\n",
        "- **coord_y**: The y-coordinate of the data point in 2D space.\n",
        "- **label**: A categorical label indicating to which circle the point belongs:\n",
        "  - `1`: Points belonging to the inner circle (radius = 2).\n",
        "  - `2`: Points belonging to the outer circle (radius = 10).\n",
        "\n",
        "#### Data Description:\n",
        "1. **Inner Circle (Label 1)**:\n",
        "   - Radius: 2.\n",
        "   - Number of points: 1500.\n",
        "   - Gaussian noise added to both x and y coordinates with a noise level of 0.2.\n",
        "2. **Outer Circle (Label 2)**:\n",
        "   - Radius: 10 units.\n",
        "   - Number of points: 1500.\n",
        "   - Gaussian noise added with the same level of 0.2.\n",
        "\n",
        "#### Dataset Properties:\n",
        "- **Number of Samples**: 3000 (1500 samples for each circle).\n",
        "- **Noise Level**: 0.2 (Gaussian noise applied independently to the x and y coordinates).\n",
        "- **Labels**: 1 for the inner circle, 2 for the outer circle.\n"
      ],
      "metadata": {
        "id": "O9ZPHcKfzFZ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Generating TNC Dataset:"
      ],
      "metadata": {
        "id": "N6h2_pTc6g2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters for both circles\n",
        "radius1 = 2\n",
        "radius2 = 10\n",
        "num_points = 1500\n",
        "noise_level = 0.2"
      ],
      "metadata": {
        "id": "gLb_d5Tf1_uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuB9sq4Mow9R"
      },
      "outputs": [],
      "source": [
        "# Function to generate noisy points on a circle with a label\n",
        "def generate_noisy_circle_points_with_labels(radius, num_points, noise_level, label):\n",
        "    # Random angles for polar coordinates\n",
        "    theta = np.random.uniform(0, 2 * np.pi, num_points)\n",
        "\n",
        "    # Coordinates on the circle (without noise)\n",
        "    coord_x = radius * np.cos(theta)\n",
        "    coord_y = radius * np.sin(theta)\n",
        "\n",
        "    # Add noise\n",
        "    coord_x += np.random.normal(0, noise_level, num_points)\n",
        "    coord_y += np.random.normal(0, noise_level, num_points)\n",
        "\n",
        "    # Create labels\n",
        "    labels = np.full(num_points, label)\n",
        "\n",
        "    return coord_x, coord_y, labels\n",
        "\n",
        "# Generate points for both circles\n",
        "coord_x1, coord_y1, labels1 = generate_noisy_circle_points_with_labels(radius1, num_points, noise_level, 1)\n",
        "coord_x2, coord_y2, labels2 = generate_noisy_circle_points_with_labels(radius2, num_points, noise_level, 2)\n",
        "\n",
        "# Combine the two circles\n",
        "coord_x = np.concatenate([coord_x1, coord_x2])\n",
        "coord_y = np.concatenate([coord_y1, coord_y2])\n",
        "labels = np.concatenate([labels1, labels2])\n",
        "\n",
        "# Create DataFrame for easy manipulation and shuffle\n",
        "data = pd.DataFrame({'coord_x': coord_x, 'coord_y': coord_y, 'label': labels})\n",
        "data = shuffle(data).reset_index(drop=True)\n",
        "\n",
        "# Save the shuffled data to a CSV file\n",
        "data.to_csv('synthetic_circle_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loading TNC dataset:"
      ],
      "metadata": {
        "id": "uVV29aXA-pbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv('synthetic_circle_data.csv')\n",
        "\n",
        "# Split features and labels\n",
        "X_TNC = data[['coord_x', 'coord_y']].values\n",
        "Y_TNC = data['label'].values"
      ],
      "metadata": {
        "id": "bz7YTqTi-vBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### Visualization:\n",
        "When plotted, the dataset exhibits two concentric, noisy circles. The inner circle is labeled as `1` and colored red, while the outer circle is labeled as `2` and colored blue. Both circles have Gaussian noise applied, which makes the data more realistic by introducing variance in the points' positions."
      ],
      "metadata": {
        "id": "NB3cYXBF0Hyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the points, color-coded by label (1 -> red, 2 -> blue)\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(data['coord_x'], data['coord_y'], c=data['label'], cmap='bwr', s=5)\n",
        "\n",
        "# Set equal aspect ratio to make the circles look accurate\n",
        "plt.gca().set_aspect('equal', adjustable='box')\n",
        "\n",
        "# Set labels and title\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('Y')\n",
        "plt.title('Synthetic Samples of Two Noisy Circles')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "18ZMkkztu8we"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"red\">Task 1: Eigenfaces (5 points) </font>\n",
        "\n",
        "**NOTE:** In this task you only work with LFW dataset.\n",
        "\n",
        "The below code is supposed to generate the \"average faces\" as well as the first \"eigen faces\" for George W Bush class.\n",
        "\n",
        "**NOTE:** For the rest of the assignment you just work with \"George W Bush\" class"
      ],
      "metadata": {
        "id": "Tqca97YW_G1u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Select \"George W Bush\" class\n",
        "Run the below code to select a specific class of faces."
      ],
      "metadata": {
        "id": "56YepiT4_iJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_name_bush = 'George W Bush'\n",
        "class_indx_bush = list(Y_names_LFW).index(class_name_bush)\n",
        "X_bush = X_LFW[Y_LFW==class_indx_bush,:]\n",
        "Y_bush = Y_LFW[Y_LFW==class_indx_bush]\n",
        "plot_faces(X_bush, Y_bush, Y_names_LFW, 2, 5)\n",
        "\n",
        "print(X_bush.shape)"
      ],
      "metadata": {
        "id": "7rSVquYb_aZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation\n",
        "In this section you need to implement `centeralize_data()` and `pca_components()` functions.\n",
        "\n",
        "We use SVD factorization in order to implement PCA. In the following link you can find useful information of how to do so. It explains the connection between PCA and SVD. https://stats.stackexchange.com/questions/134282/relationship-between-svd-and-pca-how-to-use-svd-to-perform-pca\n",
        "\n",
        "\n",
        "You may check the video with link https://youtu.be/nbBvuuNVfco?si=SfJSE85fjMUMiboK for detailed explanation of SVD."
      ],
      "metadata": {
        "id": "FuzqTJYqAKtf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def centeralize_data(data):\n",
        "    # Implement this function. Subtract the data mean from datapoints.\n",
        "    # Return centeralized data and data mean\n",
        "    # 3 points\n",
        "\n",
        "\n",
        "    ########################\n",
        "    ########################\n",
        "    #### YOUR CODE HERE ####\n",
        "    ########################\n",
        "    ########################\n",
        "\n",
        "    ##################################################################\n",
        "    ##################################################################\n",
        "    #### Make sure that data_mean has the shape (1, num_features) ####\n",
        "    ##################################################################\n",
        "    ##################################################################\n",
        "\n",
        "    return normalized_data , data_mean\n",
        "\n",
        "def pca_components(Vt, n_components):\n",
        "    # Implement this function.\n",
        "    # Return first n components (first n principal direction/axes)\n",
        "    # 2 points\n",
        "\n",
        "    ########################\n",
        "    ########################\n",
        "    #### YOUR CODE HERE ####\n",
        "    ########################\n",
        "    ########################\n",
        "\n",
        "    return Vt_first_n_components\n",
        "\n",
        "def normalized_svd(data):\n",
        "    # SVD is a matrix factorization which helps us to implement PCA.\n",
        "    # Follow the given link above to understand how it works.\n",
        "    # This function first ceteralizes the data points, and returns SVD factorization of the data set.\n",
        "    XN, data_mean = centeralize_data(data)\n",
        "    U,S,Vt = svd(XN)\n",
        "    return U, S, Vt, data_mean\n",
        "\n",
        "def average_image_class(images):\n",
        "    class_average = np.mean(images, axis = 0)\n",
        "    return class_average\n",
        "\n",
        "def eigen_face_class(images):\n",
        "    _,_,Vt,_ = normalized_svd(images)\n",
        "    return pca_components(Vt, n_components=1)\n",
        "\n",
        "def plot_class_representatives(images, class_name, aggregator):\n",
        "    f = plt.figure(figsize=(2,2))\n",
        "    subfigure = f.add_subplot(1,1,1)\n",
        "    class_representative = aggregator(images)\n",
        "\n",
        "    subfigure.imshow(class_representative.reshape((image_height, image_width)), cmap=plt.cm.gray)\n",
        "    subfigure.set_title(class_name)\n",
        "    # Removing the axes\n",
        "    plt.xticks(())\n",
        "    plt.yticks(())\n",
        "    plt.show()\n",
        "\n",
        "plot_class_representatives(X_bush, class_name_bush, aggregator=average_image_class)\n",
        "plot_class_representatives(X_bush, class_name_bush, aggregator=eigen_face_class)"
      ],
      "metadata": {
        "id": "OB9BVlPtAAmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"red\">Task 2: PCA Transformation and Reconstructing (15 points) </font>\n",
        "\n",
        "In this task, we focus on implementing two fundamental functions for Principal Component Analysis (PCA):\n",
        "\n",
        "- **`pca_transform()`**\n",
        "- **`pca_inverse_transform()`**\n"
      ],
      "metadata": {
        "id": "085UOJvMS21L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"#D2691E\">Part A (10 points): </font>\n",
        "\n",
        "- **`pca_transform()`**: Projects the original data onto a new space using PCA via Singular Value Decomposition (SVD).\n",
        "\n",
        "  ### Inputs:\n",
        "    \n",
        "    - **`X` (ndarray)**:\n",
        "      - The input data matrix to be transformed. Each row represents a sample, and each column represents a feature.\n",
        "      \n",
        "    - **`n_components` (int)**:\n",
        "      - The number of principal components to retain.\n",
        "      - Controls the dimensionality reduction by selecting the top `n_components`.\n",
        "      - For instance, setting `n_components=2` reduces the data to 2D space by projecting it onto the first two principal components.\n",
        "\n",
        "  ### Outputs:\n",
        "    \n",
        "    - **`transformed_data` (ndarray)**:\n",
        "      - The data projected onto the top `n_components` principal components, resulting in a reduced-dimension representation of the original data.\n",
        "\n",
        "    - **`Vt` (ndarray)**:\n",
        "      - The right singular vectors from SVD, needed for inverse transformation to reconstruct the original data.\n",
        "\n",
        "    - **`data_mean` (ndarray)**:\n",
        "      - The mean of the original data, which is subtracted during the transformation process and added back during the reconstruction."
      ],
      "metadata": {
        "id": "xkoZEvEuOciz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pca_transform(X, n_components):\n",
        "    \"\"\"\n",
        "    Transforms the data into a new space using PCA via SVD.\n",
        "\n",
        "    Parameters:\n",
        "    - X: ndarray\n",
        "        The input data matrix to be transformed.\n",
        "    - n_components: int\n",
        "        The number of principal components to retain.\n",
        "\n",
        "    Returns:\n",
        "    - transformed_data: ndarray\n",
        "        The data projected onto the top n_components principal components.\n",
        "    - Vt: ndarray\n",
        "        The right singular vectors from SVD, needed for inverse transformation.\n",
        "    - data_mean: ndarray\n",
        "        The mean of the original data, required to reconstruct the data.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    ########################\n",
        "    ########################\n",
        "    #### YOUR CODE HERE ####\n",
        "    ########################\n",
        "    ########################\n",
        "\n",
        "    #########################################################\n",
        "    #########################################################\n",
        "    #### Make sure that you use normalized_svd function. ####\n",
        "    #### Also make sure that n_components is valid.      ####\n",
        "    #########################################################\n",
        "    #########################################################\n",
        "\n",
        "\n",
        "    # Return the transformed data, Vt, and data_mean for reconstruction\n",
        "    return transformed_data, Vt, data_mean"
      ],
      "metadata": {
        "id": "KUSaD4vtAoWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We apply PCA transform to both datasets:\n",
        "\n",
        "For TNC dataset we set n_components=2\n",
        "\n",
        "For LFW dataset we set n_components=100\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**IMPORTANT NOTE:** Remember that in TNC dataset, we are working with X_TNC that can have two labels. But in the LFW dataset, we are just working with X_bush.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "pqfLHrn6VTBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_components = 100\n",
        "\n",
        "# Transform the X_bush data using the specified number of principal components\n",
        "T_bush, Vt_bush, mean_bush = pca_transform(X_bush, n_components)\n",
        "\n",
        "\n",
        "n_components = 2\n",
        "\n",
        "# Transform the X_TNC data using the specified number of principal components\n",
        "T_TNC, Vt_TNC, mean_TNC = pca_transform(X_TNC, n_components)"
      ],
      "metadata": {
        "id": "4SGOqkvT_fgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"#D2691E\">Part B (5 points): </font>\n",
        "\n",
        "- **`pca_inverse_transform()`**: Reconstructs the original data from its transformed representation.\n",
        "\n",
        "    - **`transformed_data` (ndarray)**:\n",
        "      - The data that has been projected into the lower-dimensional space using PCA.\n",
        "      - This is the result of the `pca_transform()` function and represents the coordinates of the original data in the new principal component space.\n",
        "\n",
        "    - **`Vt` (ndarray)**:\n",
        "      - The right singular vectors from SVD (the principal components), used for the reconstruction.\n",
        "      - This matrix is obtained from the SVD process, and only the top `n_components` vectors are used for reconstruction.\n",
        "\n",
        "    - **`n_components` (int)**:\n",
        "      - The number of principal components that were used for the transformation.\n",
        "      - Determines how many components to use in the reconstruction process.\n",
        "\n",
        "    - **`data_mean` (ndarray)**:\n",
        "      - The mean of the original data.\n",
        "      - This is used to reverse the centering operation that was applied to the data before performing PCA.\n"
      ],
      "metadata": {
        "id": "FKzDIQghQwml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pca_inverse_transform(transformed_data, Vt, n_components, data_mean):\n",
        "    \"\"\"\n",
        "    Reconstructs the original data from its transformed representation.\n",
        "\n",
        "    Parameters:\n",
        "    - transformed_data: ndarray\n",
        "        The data in the reduced-dimensional space.\n",
        "    - Vt: ndarray\n",
        "        The right singular vectors from SVD, used to reconstruct the original space.\n",
        "    - n_components: int\n",
        "        The number of principal components that were used for the transformation.\n",
        "    - data_mean: ndarray\n",
        "        The mean of the original data (used for centering).\n",
        "\n",
        "    Returns:\n",
        "    - reconstructed_data: ndarray\n",
        "        The data reconstructed back into the original space.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    ########################\n",
        "    ########################\n",
        "    #### YOUR CODE HERE ####\n",
        "    ########################\n",
        "    ########################\n",
        "\n",
        "\n",
        "    #########################################################\n",
        "    #########################################################\n",
        "    #### Make sure that you use pca_components function. ####\n",
        "    #########################################################\n",
        "    #########################################################\n",
        "\n",
        "    return reconstructed_data"
      ],
      "metadata": {
        "id": "ZDbiZF1vXqjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We apply PCA inverse transform to both new datasets:\n",
        "\n",
        "\n",
        "For TNC dataset we set n_components=2\n",
        "\n",
        "For LFW dataset we set n_components=100"
      ],
      "metadata": {
        "id": "BTjwwSr5Dnc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_components = 100\n",
        "\n",
        "# Reconstruct the X_bush data back to the original image space.\n",
        "reconstructed_bush= pca_inverse_transform(T_bush, Vt_bush, n_components, mean_bush)\n",
        "\n",
        "\n",
        "n_components = 2\n",
        "\n",
        "# Reconstruct the X_TNC data back to the original 2D space.\n",
        "reconstructed_TNC = pca_inverse_transform(T_TNC, Vt_TNC, n_components, mean_TNC)"
      ],
      "metadata": {
        "id": "pr0NvYkHDt7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TNC Visualization:\n",
        "Since we are in the 2 dimension for the circle dataset it is easy to plot the transformation results:\n",
        "\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "dxYUeoRLVLh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As shown in the TNC visualization, the dimensionality of the data is not being reduced, as we maintain the number of components at two. This ensures no information is lost. The only noticeable difference is a rotation of the data.\n",
        "\n",
        "\n",
        "Observe that here, we plot each coordinate with its corresponding label."
      ],
      "metadata": {
        "id": "tJbHP0tkRGs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the results\n",
        "fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
        "\n",
        "# Plotting Original Data for X_TNC\n",
        "axs[0].scatter(X_TNC[:, 0], X_TNC[:, 1], c=Y_TNC, cmap='bwr', s=5)\n",
        "axs[0].set_title(\"Original X_TNC\")\n",
        "\n",
        "# Plotting Transformed Data for X_TNC\n",
        "axs[1].scatter(T_TNC[:, 0], T_TNC[:, 1], c=Y_TNC, cmap='bwr', s=5)\n",
        "axs[1].set_title(\"Transformed X_TNC\")\n",
        "\n",
        "# Plotting Reconstructed Data for X_TNC\n",
        "axs[2].scatter(reconstructed_TNC[:, 0], reconstructed_TNC[:, 1], c=Y_TNC, cmap='bwr', s=5)\n",
        "axs[2].set_title(\"Reconstructed X_TNC\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CumY0G16U-ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LFW Visualization:\n",
        "\n",
        "In the case of the LFW dataset, we are working with around 500 samples, each represented in an approximately 3000-dimensional feature space. Visualizing data in such a high-dimensional space is not feasible, and even after applying PCA to reduce the dimensions to around 200, visual interpretation remains challenging. To address this, we project the data onto a 2D plane, enabling us to better visualize and understand the underlying structure. Although this 2D representation no longer reflects the pixel values of the original images, it captures the most important variance in the data, allowing us to interpret patterns and relationships more easily in the reduced space.\n",
        "\n",
        "\n",
        "As a result, we can only see the scatter plot of the first two most important new features."
      ],
      "metadata": {
        "id": "E2FBld_jUvsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the first two principal components for plotting\n",
        "pc1 = T_bush[:, 0]  # First principal component (PC1)\n",
        "pc2 = T_bush[:, 1]  # Second principal component (PC2)\n",
        "\n",
        "# Plotting the first two principal components\n",
        "plt.figure(figsize=(5, 4))\n",
        "plt.scatter(pc1, pc2, alpha=0.7, edgecolors='b')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.title('Projection onto the First Two Principal Components')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7x20frOGtn8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Moreover, some information is lost when reducing the dimensionality of the data. This can be observed by plotting the reconstructed image for a specific instance."
      ],
      "metadata": {
        "id": "FOru9WDb9H4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = 0  # Choose an index of the image you want to show (e.g., the first image)\n",
        "\n",
        "original_image = X_bush[index].reshape(image_height, image_width)\n",
        "reconstructed_image = reconstructed_bush[index].reshape(image_height, image_width)\n",
        "\n",
        "# Plotting the results\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "# Plotting Original Image from X_bush\n",
        "axs[0].imshow(original_image, cmap='gray')\n",
        "axs[0].set_title(\"Original Image (X_bush)\")\n",
        "\n",
        "\n",
        "# Plotting Reconstructed Image from X_bush\n",
        "axs[1].imshow(reconstructed_image, cmap='gray')\n",
        "axs[1].set_title(\"Reconstructed Image (X_bush)\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jPMAxUJdsuMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"red\">Task 3: Average Reconstruction Error for LFW (30 points)</font>\n",
        "Split the image dataset into train (400 images) and test (rest of the data) datasets.\n",
        "Train PCA with [2, 10, 30, 60, 100] components respectively. Reconstruction error is defined as\n",
        "\n",
        "\\begin{align}\n",
        "error=\\frac{1}{n}\\sum_{i=1}^n||x_i-reconstruct(pca(x_i))||^2_2\n",
        "\\end{align}"
      ],
      "metadata": {
        "id": "X5uebSnwF94Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"#D2691E\">Part A (20 points): </font>\n",
        "\n",
        "Plot average reconstruction error on training and testing data points with the following requirements:\n",
        "  1. X-axis shows number of components.\n",
        "  2. Y-axis shows reconstruction error.\n",
        "  3. Draw two graphs, one for training and the other line for testing.\n"
      ],
      "metadata": {
        "id": "W4VWI-c3G-Fq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of components to test in PCA\n",
        "c_components = [2, 10, 30, 60, 100]\n",
        "\n",
        "# Initialize lists to store the reconstruction errors for training and testing data\n",
        "train_errors = []\n",
        "test_errors = []\n",
        "\n",
        "    ########################\n",
        "    ########################\n",
        "    #### YOUR CODE HERE ####\n",
        "    ########################\n",
        "    ########################\n",
        "\n",
        "# Loop through each specified number of components for PCA\n",
        "for n_components in c_components:\n",
        "\n",
        "    # Apply PCA and then inverse PCA to the training data\n",
        "    ########################\n",
        "    ########################\n",
        "    #### YOUR CODE HERE ####\n",
        "    ########################\n",
        "    ########################\n",
        "\n",
        "    # Calculate the Mean Squared Error (MSE) as the reconstruction error for the training set\n",
        "    ########################\n",
        "    ########################\n",
        "    #### YOUR CODE HERE ####\n",
        "    ########################\n",
        "    ########################\n",
        "\n",
        "    # Normalize the test data. Transform the test data using the train data's PCA components\n",
        "    # and reconstruct the test data.\n",
        "    ########################\n",
        "    ########################\n",
        "    #### YOUR CODE HERE ####\n",
        "    ########################\n",
        "    ########################\n",
        "\n",
        "\n",
        "    # Calculate the Mean Squared Error (MSE) as the reconstruction error for the test set\n",
        "    ########################\n",
        "    ########################\n",
        "    #### YOUR CODE HERE ####\n",
        "    ########################\n",
        "    ########################\n",
        "\n",
        "# Print the average reconstruction errors for each number of components\n",
        "\n",
        "########################\n",
        "########################\n",
        "#### YOUR CODE HERE ####\n",
        "########################\n",
        "########################"
      ],
      "metadata": {
        "id": "n-e0TE5yHMe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_eval_results(c_components, train_error, test_error):\n",
        "  plt.figure(figsize=(6*1.5, 5*1.2))\n",
        "  plt.plot(c_components, train_error, color='b',  label='train error')\n",
        "  plt.plot(c_components, test_error, color='r', label='test error')\n",
        "  plt.xlabel('')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "plot_eval_results(c_components, train_errors, test_errors)"
      ],
      "metadata": {
        "id": "d6phYdEBHeBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"#D2691E\">Part B (10 points): </font>\n",
        "\n",
        "1. Explains the difference between the two graphs (8 points).\n",
        "\n",
        "2. What would the error be if we compute it for the TNC dataset while using two components and 2000 samples for training? (2 points)"
      ],
      "metadata": {
        "id": "TIl_Zr-_HEsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of components to test in PCA\n",
        "n_components = 2\n",
        "\n",
        "    ########################\n",
        "    ########################\n",
        "    #### YOUR CODE HERE ####\n",
        "    ########################\n",
        "    ########################\n",
        "\n",
        "    ############################################################################\n",
        "    ############################################################################\n",
        "    #### Suggestion: Copy and paste your code for part B and modify it here ####\n",
        "    ############################################################################\n",
        "    ############################################################################\n",
        "\n",
        "# Print the average reconstruction errors for each number of components\n",
        "print(\"Average reconstruction error for train data is \", train_error)\n",
        "print(\"Average reconstruction error for test data is \", test_error)"
      ],
      "metadata": {
        "id": "t8v-Y3aYZGAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"red\">Task 4: Kernel PCA (30 points)</font>\n",
        "\n",
        "KernelPCA is an extension of PCA that uses kernel methods to perform dimensionality reduction in a high-dimensional space. Unlike standard PCA, which finds linear components, Kernel PCA can capture non-linear relationships in the data by implicitly mapping it into a higher-dimensional space using a kernel function. In this task, we will use the Radial Basis Function (RBF) kernel, which is similar to a Gaussian kernel.\n",
        "\n",
        "The `gamma` parameter in the RBF kernel influences the spread of the kernel function. It is analogous to the inverse of the standard deviation (`gamma=1/sigma`) of the Gaussian. A lower `gamma` value results in a wider influence of each training point, while a higher `gamma` value makes the influence more localized. You can read more about the `gamma` parameter [here](https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html).\n",
        "\n",
        "For this task, you don't need to implement Kernel PCA from scratch; use scikit-learn's `KernelPCA` (https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.KernelPCA.html).\n",
        "\n",
        "An example setup for scikit-learn's Kernel PCA is:\n",
        "\n",
        "```python\n",
        "  KernelPCA(kernel='rbf', n_components=100, gamma=0.1, fit_inverse_transform=True)\n",
        "```\n",
        "\n",
        "Now, let's proceed with the following parts:"
      ],
      "metadata": {
        "id": "nl32M_Uyhrcz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"#D2691E\">Part A (10 points): </font>\n",
        "\n",
        "###**Apply Kernel PCA and Plot Transformed Data**:\n",
        "\n",
        "First plot the original TNC data again. Now start by applying Kernel PCA on the TNC dataset using different values of `gamma` (e.g., 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1). For each value of `gamma`, plot the transformed data to visualize the effect of the RBF kernel on the dataset. This step will help you understand how `gamma` influences the data's representation in the transformed space.\n",
        "\n",
        "\n",
        "For this part you need to plot 12 figures (one for original data, and the other 11 ones for different values of `gamma`)."
      ],
      "metadata": {
        "id": "AWMTmHK2iwx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv('synthetic_circle_data.csv')\n",
        "\n",
        "# Split features and labels\n",
        "X_TNC = data[['coord_x', 'coord_y']].values\n",
        "Y_TNC = data['label'].values"
      ],
      "metadata": {
        "id": "lUC_TL_D1iud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define different values of gamma to test\n",
        "gamma_values = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1]\n",
        "\n",
        "# Create subplots to visualize the transformed data for each gamma\n",
        "plt.figure(figsize=(20, 10))\n",
        "\n",
        "\n",
        "# Plot the original data before applying Kernel PCA\n",
        "    ########################\n",
        "    ########################\n",
        "    #### YOUR CODE HERE ####\n",
        "    ########################\n",
        "    ########################\n",
        "\n",
        "\n",
        "# Set the limits for the x and y axes\n",
        "x_limits = (-1, 1)\n",
        "y_limits = (-1, 1)\n",
        "\n",
        "# Apply Kernel PCA for each gamma value\n",
        "for idx, gamma in enumerate(gamma_values):\n",
        "\n",
        "    ########################\n",
        "    ########################\n",
        "    #### YOUR CODE HERE ####\n",
        "    ########################\n",
        "    ########################\n",
        "\n",
        "    # Plot the transformed data\n",
        "    plt.subplot(3, 4, idx + 2)\n",
        "\n",
        "    ########################\n",
        "    ########################\n",
        "    #### YOUR CODE HERE ####\n",
        "    ########################\n",
        "    ########################\n",
        "\n",
        "    # Set fixed x and y axis limits\n",
        "    plt.xlim(x_limits)\n",
        "    plt.ylim(y_limits)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mf1JA1PgjiMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"#D2691E\">Part B (5 points): </font>\n",
        "\n",
        "Based on your observations, how does Kernel PCA compare to Linear PCA on this dataset with red and blue labels? In what ways does Kernel PCA affect the distribution of the data points, particularly in terms of how well the red and blue points are organized? Choose the best value(s) for `gamma` and report it (them). What criteria did you use to determine the optimal `gamma` value?\n",
        "\n"
      ],
      "metadata": {
        "id": "dAoyY4mubTEE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"#D2691E\">Part C (5 points): </font>\n",
        "\n",
        "### **Find the Best Values for Reconstruction Error of Kernel PCA**\n",
        "\n",
        "In this part, you will tune two hyperparameters: `gamma` (values: [0.01, 0.05, 0.1, 0.5, 1]) and `n_components` (values: [2, 10, 30, 60, 100]) for the LFW dataset. Set the train size to 400 samples. Your objective is to find the best combination of `gamma` and `n_components` based on the reconstruction error. Present your results in two tables showing the reconstruction error for each combination on the training set and the test set.\n"
      ],
      "metadata": {
        "id": "UdbD98A6i7Oc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the hyperparameter ranges\n",
        "gamma_values = [0.005, 0.01, 0.05, 0.1, 0.5]\n",
        "n_components_values = [2, 10, 30, 60, 100]\n",
        "\n",
        "\n",
        "    ########################\n",
        "    ########################\n",
        "    #### YOUR CODE HERE ####\n",
        "    ########################\n",
        "    ########################\n",
        "\n",
        "\n",
        "# Loop through each combination of gamma and n_components\n",
        "for gamma in gamma_values:\n",
        "    for n_components in n_components_values:\n",
        "\n",
        "        ########################\n",
        "        ########################\n",
        "        #### YOUR CODE HERE ####\n",
        "        ########################\n",
        "        ########################\n",
        "\n",
        "# Display the results as tables\n",
        "print(\"Reconstruction Error for Training Set:\")\n",
        "print(train_errors_df)\n",
        "print(\"\\nReconstruction Error for Testing Set:\")\n",
        "print(test_errors_df)"
      ],
      "metadata": {
        "id": "sYwYRfoyicW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"#D2691E\">Part D (10 points): </font>\n",
        "\n",
        "\n",
        "### **Visualization of Reconstruction Error** (5 points)\n",
        "\n",
        "Plot the average reconstruction error on both the training and testing data with the following requirements:\n",
        "  1. Use `n_components = 60`.\n",
        "  2. Use same `gamma` as before (values: [0.01, 0.05, 0.1, 0.5, 1])\n",
        "  3. Train size = 400\n",
        "  4. The X-axis should display the different values of `gamma`.\n",
        "  5. The Y-axis should show the reconstruction error.\n",
        "  6. Draw two graphs: one for the training set and one for the test set.\n",
        "\n",
        "### **Explanation** (5 points)\n",
        "\n",
        "How does Kernel PCA compare to Linear PCA on this dataset? If Kernel PCA shows improved performance, please justify your answer. If Linear PCA performs better, explain the reasons for its effectiveness.\n",
        "\n",
        "**Hint:** Consider factors such as the choice of kernel, the characteristics of the data, and how the `gamma` parameter influences the transformed space.\n"
      ],
      "metadata": {
        "id": "qevuTOZEdMyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose n_components = 60 for visualization\n",
        "n_components = 60\n",
        "\n",
        "    ########################\n",
        "    ########################\n",
        "    #### YOUR CODE HERE ####\n",
        "    ########################\n",
        "    ########################\n",
        "\n",
        "    ########################################################\n",
        "    ########################################################\n",
        "    #### HINT: You have the values from previos section ####\n",
        "    ########################################################\n",
        "    ########################################################\n",
        "\n",
        "# Plot the results\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Plot the training errors\n",
        "plt.plot(gamma_values, train_errors, marker='o', label='Training Error')\n",
        "\n",
        "# Plot the testing errors\n",
        "plt.plot(gamma_values, test_errors, marker='o', label='Testing Error')\n",
        "\n",
        "# Labeling the plot\n",
        "plt.xlabel('Gamma Values')\n",
        "plt.ylabel('Reconstruction Error')\n",
        "plt.title(f'Reconstruction Error vs Gamma (n_components = {n_components})')\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AspvqYVyq9N_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}